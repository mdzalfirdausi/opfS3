{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2231035-e038-4db5-95c9-2ce2fe2f5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f14f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Bus:\n",
    "    def __init__(self, bus_id, pd, gs, gens):\n",
    "        self.bus_id = bus_id\n",
    "        self.pd = pd\n",
    "        self.gs = gs\n",
    "        self.gens = gens\n",
    "    def __repr__(self):\n",
    "        return (f\"Bus(pd={self.pd}, gs={self.gs}, gens={self.gens})\")\n",
    "        \n",
    "@dataclass\n",
    "class Gen:\n",
    "    def __init__(self, bus, gen_id, pmin, pmax, pstart, cost):\n",
    "        self.bus = bus\n",
    "        self.gen_id = gen_id\n",
    "        self.pmin = pmin\n",
    "        self.pmax = pmax\n",
    "        self.pstart = pstart\n",
    "        self.cost = cost\n",
    "    def __repr__(self):\n",
    "        return (f\"Generator(bus={self.bus}, pmin={self.pmin}, pmax={self.pmax}, \"\n",
    "                f\"pstart={self.pstart}, cost={self.cost})\")\n",
    "\n",
    "@dataclass\n",
    "class Line:\n",
    "    def __init__(self, line_id, rate, frombus, tobus, one_over_reactance):\n",
    "        self.line_id = line_id\n",
    "        self.rate = rate\n",
    "        self.frombus = frombus\n",
    "        self.tobus = tobus\n",
    "        self.one_over_reactance = one_over_reactance # β beta\n",
    "    def __repr__(self):\n",
    "        return (f\"TransmissionLine(rate={self.rate}, frombus={self.frombus}, \"\n",
    "                f\"tobus={self.tobus}, one_over_reactance={self.one_over_reactance})\")\n",
    "@dataclass\n",
    "class NetworkReference:\n",
    "    def __init__(self, ref, bus, bus_indices, gen, gen_indices, line, line_indices, B, pi, stdomega):\n",
    "        self.ref = ref # Dictionary of ref data\n",
    "        self.bus = bus # list of bus\n",
    "        self.bus_indices = bus_indices\n",
    "        self.gen = gen\n",
    "        self.gen_indices = gen_indices\n",
    "        self.line = line \n",
    "        self.line_indices = line_indices\n",
    "        self.B = B  # Admittance matrix\n",
    "        self.pi = pi  # π Inverse reduced admittance matrix\n",
    "        self.stdomega = stdomega  # stdω List of standard deviations\n",
    "    \n",
    "@dataclass\n",
    "class OPFScenarios:\n",
    "    def __init__(self,noptimal, ref, scenarios, solutions, cbases, rbases, whichbasis, whichscenario, nbases,rbases_all):\n",
    "        self.noptimal = noptimal\n",
    "        self.ref = ref\n",
    "        self.scenarios = scenarios\n",
    "        self.solutions = solutions\n",
    "        self.cbases = cbases\n",
    "        self.rbases = rbases\n",
    "        self.whichbasis = whichbasis\n",
    "        self.whichscenario = whichscenario\n",
    "        self.nbases = nbases\n",
    "        self.rbases_all = rbases_all\n",
    "\n",
    "@dataclass\n",
    "class SingleScenarioOPF:\n",
    "    def __init__(self, model, p, omega):\n",
    "        self.model = model\n",
    "        self.p = p\n",
    "        self.omega = omega\n",
    "\n",
    "@dataclass\n",
    "class Basis_Recourse:\n",
    "    def __init__(self, ngen, fixed, varying, basiscol, linearterms, constant):\n",
    "        self.ngen = ngen\n",
    "        self.fixed = fixed\n",
    "        self.varying = varying\n",
    "        self.basiscol = basiscol\n",
    "        self.linearterms = linearterms\n",
    "        self.constant = constant\n",
    "\n",
    "@dataclass\n",
    "class EnsembleRecourse:\n",
    "    def __init__(self, ref, baseline, recoursef):\n",
    "        self.ref = ref\n",
    "        self.baseline = baseline\n",
    "        self.recoursef = recoursef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a3ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def networkreference(data_file, sigma_scaling=0.05):\n",
    "    ref = pd.read_excel(data_file, sheet_name=['baseMVA', 'bus','gen','gencost','branch'])\n",
    "    ref['baseMVA'] = ref['baseMVA'][0].values[0]\n",
    "    ref['gen'] =  ref['gen'][ref['gen']['status'] == 1]\n",
    "    ref['gencost'] = ref['gencost'][ref['gencost'][\"gen_ID\"].isin(ref['gen'][\"gen_ID\"].tolist())]\n",
    "    \n",
    "    bus_gens = ref[\"gen\"].groupby(\"bus_i\")[\"gen_ID\"].unique().to_dict()\n",
    "    \n",
    "    for b in ref[\"bus\"][\"bus_i\"]:\n",
    "        if b not in bus_gens:\n",
    "            bus_gens[b]=[]\n",
    "            \n",
    "    scale_factors = np.array([ref['baseMVA']**2, ref['baseMVA'], 1])\n",
    "    \n",
    "    gen = {ref['gen'].loc[i,\"gen_ID\"]: Gen(\n",
    "                ref['gen'].loc[i,\"bus_i\"],\n",
    "                ref['gen'].loc[i,\"gen_ID\"],\n",
    "                ref['gen'].loc[i,\"Pmin\"]/ref['baseMVA'],\n",
    "                ref['gen'].loc[i,\"Pmax\"]/ref['baseMVA'],\n",
    "                ref['gen'].loc[i,\"Pg\"]/ref['baseMVA'],\n",
    "                np.array(ref['gencost'].loc[i,['c2','c1','c0']])*scale_factors\n",
    "            ) for i in ref['gen'].index}\n",
    "          \n",
    "    \n",
    "    bus = {ref['bus'].loc[i,\"bus_i\"]: Bus(\n",
    "            ref['bus'].loc[i,\"bus_i\"],\n",
    "            ref['bus'].loc[i,\"Pd\"]/ref['baseMVA'],\n",
    "            ref['bus'].loc[i,\"Gs\"]/ref['baseMVA'],\n",
    "            bus_gens[ref['bus'].loc[i,\"bus_i\"]],\n",
    "            ) for i in ref['bus'].index}\n",
    "          \n",
    "    \n",
    "    line = {ref['branch'].loc[l,\"line_ID\"]: Line(\n",
    "            l+1, \n",
    "            ref['branch'].loc[l,\"rateA\"]/ref['baseMVA'],\n",
    "            ref['branch'].loc[l,\"bus_i\"],\n",
    "            ref['branch'].loc[l,\"bus_j\"],\n",
    "            1/ ref['branch'].loc[l,\"x\"]\n",
    "            ) for l in ref['branch'].index\n",
    "            }\n",
    "           \n",
    "    \n",
    "    ref['ref_buses'] = ref['bus'][ref['bus'].type==3]\n",
    "    \n",
    "    B = admittancematrix(ref)\n",
    "    bus_IDs = sorted(ref['bus'][\"bus_i\"].tolist())\n",
    "    bus_IDs_Index = {b:i for i,b in enumerate(bus_IDs)}\n",
    "    B_mat = np.zeros((len(bus_IDs),len(bus_IDs)))\n",
    "    for b1 in bus_IDs:\n",
    "        for b2 in bus_IDs:\n",
    "            B_mat[bus_IDs_Index[b1],bus_IDs_Index[b2]] = B[b1,b2]\n",
    "    B_red = remove_rows_and_columns(B_mat, \n",
    "                                    bus_IDs_Index[ref['ref_buses'][\"bus_i\"].values[0]], \n",
    "                                    bus_IDs_Index[ref['ref_buses'][\"bus_i\"].values[0]])\n",
    "    \n",
    "    pi_mat = np.linalg.inv(B_red)\n",
    "    \n",
    "    pi_mat = add_row_and_column(pi_mat, \n",
    "                            bus_IDs_Index[ref['ref_buses'][\"bus_i\"].values[0]], \n",
    "                            bus_IDs_Index[ref['ref_buses'][\"bus_i\"].values[0]])\n",
    "    pi = defaultdict(float)\n",
    "    for b1 in bus_IDs:\n",
    "        for b2 in bus_IDs:\n",
    "            pi[b1,b2]=pi_mat[bus_IDs_Index[b1],bus_IDs_Index[b2]] \n",
    "    \n",
    "    stdomega = [sigma_scaling*(ref['bus'].loc[b,\"Pd\"]/ref['baseMVA']) for b in ref['bus'].index]\n",
    "    bus_indices = [i for i in ref['bus']['bus_i']]\n",
    "    gen_indices = [i for i in ref['gen']['gen_ID']]\n",
    "    line_indices = [i for i in ref['branch']['line_ID']]\n",
    "\n",
    "    return NetworkReference(ref,bus, bus_indices,gen,gen_indices,line,line_indices,B,pi,stdomega)\n",
    "\n",
    "def admittancematrix(ref):\n",
    "    nbus = len(ref['bus'])\n",
    "    B = defaultdict(float)\n",
    "    for br in ref['branch'].index:\n",
    "        f_bus = ref['branch'].loc[br,\"bus_i\"]\n",
    "        t_bus = ref['branch'].loc[br,\"bus_j\"]\n",
    "        B[f_bus, t_bus] += (-ref['branch'].loc[br,\"x\"]/(ref['branch'].loc[br,\"x\"]**2+ref['branch'].loc[br,\"r\"]**2)) # imaginary part of admittance, x/(x^2+r^2)\n",
    "        B[t_bus, f_bus] += (-ref['branch'].loc[br,\"x\"]/(ref['branch'].loc[br,\"x\"]**2+ref['branch'].loc[br,\"r\"]**2)) \n",
    "        B[f_bus, f_bus] += (ref['branch'].loc[br,\"x\"]/(ref['branch'].loc[br,\"x\"]**2+ref['branch'].loc[br,\"r\"]**2))\n",
    "        B[t_bus, t_bus] += (ref['branch'].loc[br,\"x\"]/(ref['branch'].loc[br,\"x\"]**2+ref['branch'].loc[br,\"r\"]**2))\n",
    "    return B\n",
    "\n",
    "def remove_rows_and_columns(matrix, rows_to_remove, cols_to_remove):\n",
    "    matrix = np.delete(matrix, rows_to_remove, axis=0)  # Remove rows\n",
    "    matrix = np.delete(matrix, cols_to_remove, axis=1)  # Remove columns\n",
    "    return matrix\n",
    "\n",
    "def add_row_and_column(matrix, row_index, col_index):\n",
    "    matrix = np.insert(matrix, row_index, 0, axis=0)\n",
    "    matrix = np.insert(matrix, col_index, 0, axis=1)\n",
    "    return matrix\n",
    "\n",
    "def cost(ref,p):\n",
    "    try:\n",
    "        return gp.quicksum(ref.gen[g].cost[0]*p[g] + ref.gen[g].cost[1]*p[g] + ref.gen[g].cost[2] for g in ref.gen_indices)\n",
    "    except IndexError:\n",
    "        return gp.quicksum(ref.gen[g].cost[0]*p[g-1] + ref.gen[g].cost[1]*p[g-1] + ref.gen[g].cost[2] for g in ref.gen_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0defdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def singlescenarioopf(ref):\n",
    "    model = gp.Model()\n",
    "    p = model.addVars(ref.gen_indices, vtype=gp.GRB.CONTINUOUS, name='p',\n",
    "                    lb=[ref.gen[g].pmin for g in ref.gen_indices],\n",
    "                    ub=[ref.gen[g].pmax for g in ref.gen_indices])\n",
    "    \n",
    "    p.start = [ref.gen[g].pstart for g in ref.gen_indices]\n",
    "    omega = model.addVars(ref.bus_indices, vtype=gp.GRB.CONTINUOUS, name='omega')\n",
    "\n",
    "    def busvalue(ref, i): \n",
    "        return gp.quicksum(p[g] for g in ref.bus[i].gens) + omega[i] - ref.bus[i].pd - ref.bus[i].gs\n",
    "    \n",
    "    def theta(ref, busvalue, i): \n",
    "        return gp.quicksum(ref.pi[i,j]*busvalue(ref,j) for j in ref.bus_indices)\n",
    "    \n",
    "    def lineflow(l): \n",
    "        return ref.line[l].one_over_reactance*(\n",
    "        theta(ref,busvalue,ref.line[l].frombus) - theta(ref,busvalue,ref.line[l].tobus)\n",
    "        )\n",
    "    \n",
    "    model.addConstrs((lineflow(l) <= ref.line[l].rate for l in ref.line_indices), name='c')\n",
    "\n",
    "    model.addConstrs((lineflow(l) >= -ref.line[l].rate for l in ref.line_indices), name='c')\n",
    "\n",
    "    model.addConstr(0 == gp.quicksum(gp.quicksum(p[g] for g in ref.bus[b].gens) +omega[b]-ref.bus[b].pd-ref.bus[b].gs for b in ref.bus_indices), name='c')\n",
    "    \n",
    "    model.setObjective(cost(ref,p), gp.GRB.MINIMIZE)\n",
    "    \n",
    "    return SingleScenarioOPF(model, p, omega)\n",
    "\n",
    "def opfscenarios_dist(ref, m, nsamples=1000):\n",
    "    nonzeroindices = [i for i in range(len(ref.stdomega)) if ref.stdomega[i] > 1e-5]\n",
    "    mean = np.zeros(len(nonzeroindices))\n",
    "    cov = np.diag(list(map(ref.stdomega.__getitem__, nonzeroindices)))**2\n",
    "    omega = multivariate_normal.rvs(mean=mean, cov=cov, size=nsamples)\n",
    "    omega_samples = np.zeros((len(ref.bus), nsamples))\n",
    "    omega_samples[nonzeroindices] = omega.T if omega.ndim == 2 else omega[:, np.newaxis]\n",
    "    return opfscenarios(ref, m, omega_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59359814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opfscenarios(ref, m, omega_samples):\n",
    "    nsamples = omega_samples.shape[1]\n",
    "    status = [None] * nsamples\n",
    "    soln_p = np.zeros((nsamples, len(ref.gen)))\n",
    "    cbases = {}\n",
    "    rbases = {}\n",
    "    noptimal = 0\n",
    "    nbases = {}\n",
    "    rbases_all = {}\n",
    "    for s in tqdm(range(nsamples)):\n",
    "        for idx, num in enumerate(m.omega):\n",
    "            m.omega[num].lb = omega_samples[idx][s]\n",
    "            m.omega[num].ub = omega_samples[idx][s]\n",
    "        m.model.setParam('OutputFlag', 0) # suppress the output\n",
    "        # m.model.setParam('FeasibilityTol', 1e-2) # Default value: 1e-6 Minimum value: 1e-9 Maximum value: 1e-2\n",
    "        m.model.optimize()\n",
    "        status[s] = m.model.status\n",
    "        if status[s] == gp.GRB.OPTIMAL:\n",
    "            soln_p[s,:] = np.array([v.X for v in m.model.getVars() if 'p' in v.VarName])\n",
    "            noptimal += 1\n",
    "            cbasis = tuple(m.model.getAttr('Vbasis', m.model.getVars()))\n",
    "            rbasis = tuple(m.model.getAttr('Cbasis', m.model.getConstrs()))\n",
    "            cbases[cbasis] = cbases.get(cbasis, [])\n",
    "            rbases[rbasis] = rbases.get(rbasis, [])\n",
    "            cbases[cbasis].append(noptimal)\n",
    "            rbases[rbasis].append(noptimal)\n",
    "            nbases[s] = len(rbases)\n",
    "            rbases_all[s] = rbasis\n",
    "    assert noptimal == sum(1 for stat in status if stat == gp.GRB.OPTIMAL), 'Mismatch in optimal scenario count'\n",
    "    sample_p = soln_p[np.array(status)==gp.GRB.OPTIMAL,:]\n",
    "    sample_omega = omega_samples[:, np.array(status)==gp.GRB.OPTIMAL]\n",
    "    colbases = list(cbases.keys())\n",
    "    rowbases = list(rbases.keys())\n",
    "    whichcol = dict(zip(colbases, range(len(colbases))))\n",
    "    whichrow = dict(zip(rowbases, range(len(rowbases))))\n",
    "    whichbasis = np.zeros((noptimal, 2), dtype=int)\n",
    "    for ckey in cbases.keys():\n",
    "        whichbasis[cbases.get(ckey)[-1]-1,0] = whichcol[ckey]\n",
    "    for rkey in rbases.keys():\n",
    "        whichbasis[rbases.get(rkey)[-1]-1,1] = whichrow[rkey]\n",
    "    whichscenario = {}\n",
    "    for i in range(noptimal):\n",
    "        basiskey = (whichbasis[i,0], whichbasis[i,1])\n",
    "        whichscenario[basiskey] = whichscenario.get(basiskey, [])\n",
    "        whichscenario[basiskey].append(i)\n",
    "    return OPFScenarios(noptimal, ref, sample_omega, sample_p, colbases, rowbases, whichbasis, whichscenario, nbases, rbases_all)\n",
    "\n",
    "def get_opf_solution(m, omega_samples):\n",
    "    for idx, num in enumerate(m.omega):\n",
    "        m.omega[num].lb = omega_samples[idx]\n",
    "        m.omega[num].ub = omega_samples[idx]\n",
    "    m.model.optimize()\n",
    "    assert m.model.status == gp.GRB.OPTIMAL, 'bismillah'\n",
    "    return np.array([v.X for v in m.model.getVars() if 'p' in v.VarName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5007cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasisRecourse(ref, m, cbasis, rbasis):\n",
    "    br = Basis_Recourse(len(ref.gen), {}, [], {}, np.array([]), [])\n",
    "    basic_indices = []\n",
    "    for i, _ in enumerate(ref.gen_indices):\n",
    "        if cbasis[i] == 0: #basic :Basic\n",
    "            basic_indices.append(i)\n",
    "        elif cbasis[i] == -1: #non-basic at lower bound elseif cbasis[i] == :NonbasicAtLower || (cbasis[i] == :Fixed ??)\n",
    "            br.fixed[i] = m.model.getVars()[i].LB\n",
    "        elif cbasis[i] == -2: #non-basic at upper bound :NonbasicAtUpper\n",
    "            br.fixed[i] = m.model.getVars()[i].UB\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognised basis status: {} at index {}\".format(scenarios.cbases[0][i], i))\n",
    "    br.varying = basic_indices\n",
    "    count = 0\n",
    "    numbasic = sum(count+1 for i in rbasis if i != 0) #non-basic numbasic = sum(rbasis .!== :Basic)\n",
    "    basiscol = br.basiscol = dict(zip(basic_indices, range(numbasic)))\n",
    "    assert len(basic_indices) == numbasic, \"Mismatch: len(basic_indices) != numbasic\"\n",
    "    assert basic_indices == sorted(basic_indices), \"basic_indices is not sorted\"\n",
    "    assert len(m.model.getA().toarray()) == 2*len(ref.line)+1, 'bismillah'\n",
    "    basis = np.zeros((numbasic, numbasic), dtype=float)\n",
    "    omega_matrix = np.zeros((numbasic, len(ref.bus)), dtype=float)\n",
    "    c = 0\n",
    "    for i in range(2*len(ref.line)+1): #     for i in 1:(2*ref.nline + 1)\n",
    "        terms = m.model.getA().toarray()[i] #        terms = m.model.linconstr[i].terms\n",
    "        if rbasis[i] != 0: # in gurobipy, possible value only 0 and -1; if rbasis[i] !== :Basic\n",
    "            c += 1\n",
    "            rhs = m.model.RHS[i] #  rhs = if rbasis[i] == :NonbasicAtLower || rbasis[i] == :Fixedm.model.linconstr[i].lbelseif rbasis[i] == :NonbasicAtUpperm.model.linconstr[i].ub else\n",
    "# # # chatgpt: model.RHS[i]) already reflects the complete bound as intended in the model formulation. There is no separate \"constant\" component returned. no need rhs -= terms.constant\n",
    "            for num, coeff in enumerate(terms): # for (v,coeff) in zip(terms.vars, terms.coeffs)\n",
    "                if num+1 <= len(ref.gen): # first len(ref.gen) terms are decision variable p                 if v.col <= ref.ngen # power generator\n",
    "                    if cbasis[num] == 0: # if cbasis[v.col] == :Basic\n",
    "                        basis[c-1, basiscol[num]] += coeff # basis[c,basiscol[v.col]] += coeff\n",
    "                    else:\n",
    "                        rhs -= coeff*br.fixed[num] # rhs -= coeff*br.fixed[v.col]\n",
    "                else:\n",
    "                    assert num <= len(ref.gen) + len(ref.bus) # @assert v.col <= ref.ngen + ref.nbus # uncertainty\n",
    "                    assert cbasis[num] != 0 # @assert cbasis[v.col] !== :Basic # they are fixed for each scenario\n",
    "                    omega_matrix[c-1, num-len(ref.gen)] -= coeff # ωmatrix[c,v.col-ref.ngen] -= coeff\n",
    "            br.constant.append(rhs) # push!(br.constant, rhs)\n",
    "    assert c == numbasic == len(br.varying) == len(br.constant), \"bismillah\"\n",
    "    br.linearterms = np.linalg.inv(basis)@omega_matrix\n",
    "    br.constant = np.linalg.inv(basis)@br.constant\n",
    "    return br\n",
    "def get_opf_solution_br(br,omega):\n",
    "    basic_values = br.linearterms@omega + br.constant\n",
    "    soln = np.zeros(br.ngen, dtype=float)\n",
    "    for i in br.fixed.keys():\n",
    "        soln[i] = br.fixed[i]\n",
    "    for i in br.varying:\n",
    "        soln[i] = basic_values[br.basiscol[i]]\n",
    "    return soln\n",
    "def theta(ref, busvalue, i):\n",
    "    return gp.quicksum(ref.pi[i,j]*busvalue(ref,j) for j in ref.bus_indices)\n",
    "def lineflow(ref, p, omega, l):\n",
    "    def busvalue(ref, i):\n",
    "        result = omega[i] - ref.bus[i].pd - ref.bus[i].gs\n",
    "        if ref.bus[i].gens:\n",
    "            result += sum(p[g-1] for g in ref.bus[i].gens)\n",
    "        return result\n",
    "    return ref.line[l].one_over_reactance*(theta(ref,busvalue,ref.line[l].frombus-1) - theta(ref,busvalue,ref.line[l].tobus-1))\n",
    "def nviolations(ref, p, omega, atol=1e-5):\n",
    "    return ngenerationviolations(ref, p) + ntransmissionviolations(ref, p, omega)\n",
    "def ngenerationviolations(ref, p, atol=1e-5):\n",
    "    try:\n",
    "        return sum(ref.gen[i].pmin - atol > p[i] for i in ref.gen_indices)+\\\n",
    "           sum(ref.gen[i].pmax + atol < p[i] for i in ref.gen_indices)\n",
    "    except IndexError:\n",
    "        return sum(ref.gen[i].pmin - atol > p[i-1] for i in ref.gen_indices)+\\\n",
    "           sum(ref.gen[i].pmax + atol < p[i-1] for i in ref.gen_indices)\n",
    "def ntransmissionviolations(ref, p, omega, atol=1e-5):\n",
    "    bus_idx_map = {k:v for k,v in zip(ref.bus_indices, range(len(ref.bus_indices)))}\n",
    "    def lineflow(ref, p, omega, l):\n",
    "        def busvalue(ref, i):\n",
    "            result = omega[bus_idx_map[i]] - ref.bus[i].pd - ref.bus[i].gs\n",
    "            if len(ref.bus[i].gens) > 0:\n",
    "                result += sum(p[g-1] for g in ref.bus[i].gens)\n",
    "            return result\n",
    "        return ref.line[l].one_over_reactance*(theta(ref,busvalue,ref.line[l].frombus) - theta(ref,busvalue,ref.line[l].tobus))\n",
    "    if omega.ndim ==2:\n",
    "        return sum(ntransmissionviolations_vector(ref, p, omega[i,:], atol=atol) for i in range(omega.shape[0]))\n",
    "    else:\n",
    "        return sum(abs(lineflow(ref, p, omega, l).getValue()) > ref.line[l].rate + atol for _, l in enumerate(ref.line_indices))\n",
    "def ntransmissionviolations_vector(ref, p, omega, atol=1e-5):\n",
    "    sum(abs(lineflow(ref, p, omega, l).getValue())> ref.line[l].rate + atol for l in ref.line_indices) \n",
    "def nviolations(ref, p, omega, atol=1e-5):\n",
    "    return ngenerationviolations(ref, p) + ntransmissionviolations(ref, p, omega)    \n",
    "def get_opf_solution_ensemble(er, omega):\n",
    "    incumbent_p = get_opf_solution_br(er.baseline, omega)\n",
    "    incumbent_cost = cost(er.ref, incumbent_p)\n",
    "    feasible_p = nviolations(er.ref, incumbent_p, omega)\n",
    "    for rf in er.recoursef:\n",
    "        p = get_opf_solution_br(rf, omega)\n",
    "        if nviolations(er.ref, p, omega) == 0: # feasible solution\n",
    "            curr_cost = cost(er.ref, p)\n",
    "            if not feasible_p:\n",
    "                incumbent_cost = curr_cost\n",
    "                incumbent_p = p\n",
    "                feasible_p = True\n",
    "            elif curr_cost.getValue() < incumbent_cost.getValue():\n",
    "                incumbent_cost = curr_cost\n",
    "                incumbent_p = p\n",
    "    return incumbent_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a2b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:28<00:00, 172.74it/s]\n"
     ]
    }
   ],
   "source": [
    "data_file='./excel_outputs/pglib_opf_case240_pserc.xlsx'\n",
    "nsamples = 5000\n",
    "ref = networkreference(data_file, sigma_scaling=0.03)\n",
    "m = singlescenarioopf(ref)\n",
    "scenarios = opfscenarios_dist(ref, m, nsamples = nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "br0 = BasisRecourse(ref, m, scenarios.cbases[0], scenarios.rbases[0])\n",
    "br1 = BasisRecourse(ref, m, scenarios.cbases[1], scenarios.rbases[1])\n",
    "br2 = BasisRecourse(ref, m, scenarios.cbases[2], scenarios.rbases[2])\n",
    "br3 = BasisRecourse(ref, m, scenarios.cbases[3], scenarios.rbases[3])\n",
    "get_opf_solution_br(br0,omega)\n",
    "\n",
    "ensemble = EnsembleRecourse(ref, br0, [br1,br2,br3])\n",
    "omega = scenarios.scenarios[:,1]\n",
    "\n",
    "get_opf_solution_ensemble(ensemble, omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1\n",
    "# np.random.seed(2)\n",
    "data_file='./excel_outputs/pglib_opf_case240_pserc.xlsx'\n",
    "nsamples = 5000\n",
    "# ref001 = networkreference(data_file, sigma_scaling=0.01)\n",
    "# ref002 = networkreference(data_file, sigma_scaling=0.02)\n",
    "ref003 = networkreference(data_file, sigma_scaling=0.03)\n",
    "# ref004 = networkreference(data_file, sigma_scaling=0.04)\n",
    "# ref005 = networkreference(data_file, sigma_scaling=0.05)\n",
    "# m001 = singlescenarioopf(ref001)\n",
    "# m002 = singlescenarioopf(ref002)\n",
    "m003 = singlescenarioopf(ref003)\n",
    "# m004 = singlescenarioopf(ref004)\n",
    "# m005 = singlescenarioopf(ref005)\n",
    "# scenarios001 = opfscenarios_dist(ref001, m001, nsamples = nsamples)\n",
    "# scenarios002 = opfscenarios_dist(ref002, m002, nsamples = nsamples)\n",
    "scenarios003 = opfscenarios_dist(ref003, m003, nsamples = nsamples)\n",
    "# scenarios004 = opfscenarios_dist(ref004, m004, nsamples = nsamples)\n",
    "# scenarios005 = opfscenarios_dist(ref005, m005, nsamples = nsamples)\n",
    "# m.model.write('gur.lp')\n",
    "# ref003_test = networkreference(data_file, sigma_scaling=0.03)\n",
    "# m003_test = singlescenarioopf(ref003_test)\n",
    "# scenarios003_test = opfscenarios_dist(ref003_test, m003_test, nsamples = nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b955034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1\n",
    "# scenarios.nbases\n",
    "# x1 = list(scenarios001.nbases.keys())\n",
    "# y1 = list(scenarios001.nbases.values())\n",
    "# x2 = list(scenarios002.nbases.keys())\n",
    "# y2 = list(scenarios002.nbases.values())\n",
    "# x3 = list(scenarios003.nbases.keys())\n",
    "# y3 = list(scenarios003.nbases.values())\n",
    "# x4 = list(scenarios004.nbases.keys())\n",
    "# y4 = list(scenarios004.nbases.values())\n",
    "# x5 = list(scenarios005.nbases.keys())\n",
    "# y5 = list(scenarios005.nbases.values())\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(x1, y1, marker='o', linestyle='-', color='b', label=\"σscaling = 0.01\")\n",
    "# plt.plot(x2, y2, marker='s', linestyle='--', color='g', label=\"σscaling = 0.02\")\n",
    "# plt.plot(x3, y3, marker='^', linestyle='-.', color='r', label=\"σscaling = 0.03\")\n",
    "# plt.plot(x4, y4, marker='D', linestyle=':', color='c', label=\"σscaling = 0.04\")\n",
    "# plt.plot(x5, y5, marker='v', linestyle=(0, (5, 1)), color='mb', label=\"σscaling = 0.05\")\n",
    "# plt.title(\"Plot of wk Dictionary\")\n",
    "# plt.xlabel(\"Index\")\n",
    "# plt.ylabel(\"Value\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3\n",
    "def get_coverage(train_bases, test_bases):\n",
    "    training_set = set(train_bases.values())\n",
    "    covered = sum(1 for b in test_bases.values() if b in training_set)\n",
    "    return covered / len(test_bases)\n",
    "\n",
    "# coverage_value = get_coverage(scenarios003.rbases_all, scenarios003_test.rbases_all)\n",
    "# print(f\"Cumulative out-of-sample coverage: {coverage_value:.4f}\")\n",
    "\n",
    "sample_sizes = [100, 200, 500, 1000, 2500, 5000]\n",
    "coverage_results = []\n",
    "for n in sample_sizes:\n",
    "    scenarios_train = opfscenarios_dist(ref003, m003, nsamples=n)\n",
    "    coverage = get_coverage(scenarios_train.rbases_all, scenarios003_test.rbases_all)\n",
    "    coverage_results.append((n, coverage))\n",
    "    print(f\"Samples: {n}, Out-of-sample coverage: {coverage:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 2\n",
    "data_file = './excel_outputs/pglib_opf_case300_ieee.xlsx'\n",
    "def cumulative_coverage_progress(scenarios_train, test_rbases_all):\n",
    "    discovered = set()\n",
    "    test_bases = list(test_rbases_all.values())\n",
    "    progress = []\n",
    "    \n",
    "    for i in scenarios_train.rbases_all.keys():\n",
    "        discovered.add(scenarios_train.rbases_all[i])\n",
    "        covered = sum(1 for b in test_bases if b in discovered)\n",
    "        progress.append(covered / len(test_bases))\n",
    "    return progress\n",
    "\n",
    "# σ-scaling values to plot\n",
    "scaling_values = [0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "colors = ['blue', 'green', 'darkorange', 'purple', 'gold']\n",
    "labels = [f'σscaling = {s:.2f}' for s in scaling_values]\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "for sigma, color, label in zip(scaling_values, colors, labels):\n",
    "    ref_train = networkreference(data_file, sigma_scaling=sigma)\n",
    "    m_train = singlescenarioopf(ref_train)\n",
    "    scenarios_train = opfscenarios_dist(ref_train, m_train, nsamples=10000)\n",
    "\n",
    "    # fixed test set for this σ\n",
    "    ref_test = networkreference(data_file, sigma_scaling=sigma)\n",
    "    m_test = singlescenarioopf(ref_test)\n",
    "    scenarios_test = opfscenarios_dist(ref_test, m_test, nsamples=10000)\n",
    "\n",
    "    coverage_progress = cumulative_coverage_progress(scenarios_train, scenarios_test.rbases_all)\n",
    "\n",
    "    plt.plot(range(1, len(coverage_progress) + 1), coverage_progress, label=label, color=color)\n",
    "\n",
    "plt.xlabel(\"Number of Training Scenarios\")\n",
    "plt.ylabel(\"Proportion of Scenarios\")\n",
    "plt.title(\"Proportion of all 10’000 scenarios covered by the already identified bases\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a20fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_bases_by_frequency(scenarios):\n",
    "    from collections import Counter\n",
    "    basis_list = list(scenarios.rbases_all.values())\n",
    "    counter = Counter(basis_list)\n",
    "    ranked_bases = [basis for basis, _ in counter.most_common()]\n",
    "    return ranked_bases\n",
    "\n",
    "def ensemble_policy_performance(ref, test_scenarios, ranked_bases, max_k_list, verbose=True):\n",
    "    results = []\n",
    "    omega_test = test_scenarios.scenarios\n",
    "    true_bases = list(test_scenarios.rbases_all.values())\n",
    "\n",
    "    for k in max_k_list:\n",
    "        ensemble = ranked_bases[:k]\n",
    "        feasible_count = 0\n",
    "        optimal_count = 0\n",
    "\n",
    "        for i in range(test_scenarios.noptimal):\n",
    "            omega_i = omega_test[:, i]\n",
    "            true_basis = true_bases[i]\n",
    "            found_feasible = False\n",
    "            found_optimal = False\n",
    "\n",
    "            for b in ensemble:\n",
    "                br = BasisRecourse(ref, m003, scenarios003.cbases[0], b)  # You can use any cbasis (not used)\n",
    "                p_candidate = get_opf_solution_br(br, omega_i)\n",
    "\n",
    "                # Check feasibility\n",
    "                if nviolations(ref, p_candidate, omega_i) == 0:\n",
    "                    found_feasible = True\n",
    "                    if b == true_basis:\n",
    "                        found_optimal = True\n",
    "                    break  # Stop after first feasible\n",
    "\n",
    "            if found_feasible:\n",
    "                feasible_count += 1\n",
    "            if found_optimal:\n",
    "                optimal_count += 1\n",
    "\n",
    "        prop_feas = feasible_count / test_scenarios.noptimal\n",
    "        prop_opt = optimal_count / test_scenarios.noptimal\n",
    "        results.append((k, prop_opt, prop_feas))\n",
    "        if verbose:\n",
    "            print(f\"#Bases: {k}, Optimal: {prop_opt:.3f}, Feasible: {prop_feas:.3f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d01fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.write('gur.lp')\n",
    "# https://jump.dev/JuMP.jl/v0.18/refmodel.html?highlight=write\n",
    "# writeLP(m.model,\"jul.lp\";genericnames=false) - write the model to filename in the LP file format. Set genericnames=false for user-defined variable names.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
